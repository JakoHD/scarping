# Scrapin-OCC

Scraper de OCC (OCC Mundial) usando Puppeteer con interfaz web.

## üöÄ Despliegue en Vercel

Este proyecto est√° configurado para desplegarse f√°cilmente en Vercel.

### Estructura del Proyecto

```
Scrapin-OCC/
‚îú‚îÄ‚îÄ api/                    # Funciones serverless de Vercel
‚îÇ   ‚îî‚îÄ‚îÄ scrape.js          # Endpoint para el scraper
‚îú‚îÄ‚îÄ web-interface/         # Interfaz web
‚îÇ   ‚îú‚îÄ‚îÄ index.html         # P√°gina principal
‚îÇ   ‚îú‚îÄ‚îÄ server.js          # Servidor Express
‚îÇ   ‚îú‚îÄ‚îÄ vacantes.html      # P√°gina de resultados
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ scrape.js              # L√≥gica del scraper
‚îú‚îÄ‚îÄ vercel.json           # Configuraci√≥n de Vercel
‚îú‚îÄ‚îÄ package.json          # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md             # Este archivo
```

### Pasos para Desplegar

1. **Instalar Vercel CLI** (opcional):
   ```bash
   npm i -g vercel
   ```

2. **Conectar con Vercel**:
   - Ve a [vercel.com](https://vercel.com)
   - Crea una cuenta o inicia sesi√≥n
   - Conecta tu repositorio de GitHub/GitLab/Bitbucket

3. **Desplegar**:
   - Si usas Vercel CLI:
     ```bash
     vercel
     ```
   - Si usas la interfaz web:
     - Importa tu repositorio
     - Vercel detectar√° autom√°ticamente la configuraci√≥n

4. **Variables de Entorno** (opcional):
   - En el dashboard de Vercel, ve a Settings > Environment Variables
   - Agrega cualquier variable de entorno necesaria

### Configuraci√≥n

El proyecto incluye:

- **`vercel.json`**: Configuraci√≥n completa de rutas y builds
  - Rutas para API serverless
  - Rutas para archivos est√°ticos
  - Configuraci√≥n de CORS
  - Timeouts extendidos para scraping
- **`api/scrape.js`**: Endpoint serverless para el scraper
- **`web-interface/server.js`**: Servidor Express para la interfaz web

### Rutas Disponibles

Una vez desplegado, tendr√°s acceso a:

- **`/`** - P√°gina principal (interfaz de b√∫squeda)
- **`/vacantes`** - P√°gina de resultados de vacantes
- **`/api/scrape`** - Endpoint API para scraping
- **`/resultados.json`** - Archivo JSON con resultados
- **`/resultados.csv`** - Archivo CSV con resultados
- **`/resultados.xlsx`** - Archivo Excel con resultados
- **`/resultados.pdf`** - Archivo PDF con resultados

### Uso

Una vez desplegado, puedes:

1. Acceder a la interfaz web en la URL de Vercel
2. Usar el endpoint API directamente: `https://tu-proyecto.vercel.app/api/scrape`
3. Integrar el scraper en otras aplicaciones
4. Acceder a los archivos de resultados generados

### Notas Importantes

- El scraper usa Puppeteer con configuraci√≥n especial para Vercel
- Los archivos se generan solo en desarrollo local (no en Vercel)
- El proyecto est√° limitado a 5 p√°ginas por b√∫squeda para evitar timeouts
- Se requiere Node.js 18+ para el despliegue
- CORS est√° configurado para permitir requests externos
- Timeouts extendidos (60s) para funciones de scraping

### Desarrollo Local

```bash
# Instalar dependencias
npm install

# Ejecutar en desarrollo
npm run dev
```

### Troubleshooting

- Si hay problemas con Puppeteer en Vercel, revisa los logs en el dashboard
- Aseg√∫rate de que todas las dependencias est√©n en `package.json`
- Verifica que la versi√≥n de Node.js sea compatible (18+)
- Si hay problemas de CORS, verifica la configuraci√≥n en `vercel.json`
- Para problemas de rutas, revisa la configuraci√≥n de `routes` en `vercel.json`

### Configuraci√≥n Avanzada

El proyecto incluye configuraciones avanzadas para Vercel:

- **Headers personalizados** para CORS
- **Rewrites** para URLs limpias
- **Clean URLs** habilitadas
- **Timeouts extendidos** para funciones serverless
- **Manejo de archivos est√°ticos** optimizado
